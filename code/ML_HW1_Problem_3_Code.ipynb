{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a)\n",
      "P(Y=1) is equal to 0.4\n",
      "P (Xi=1|Y=1)  [ 0.75  0.    0.75  0.5   0.25]  \n",
      "P(Xi=1|Y=-1) [ 0.5  0.83333333  0.66666667  0.83333333  0.33333333])\n",
      "\n",
      "b)\n",
      "for  0 0 0 0 0\n",
      "p(x1=0,x2=0,x3=0,x4=0,x5=0|y=1)p(y=1) = 0.009375 \n",
      "p(x1=0,x2=0,x3=0,x4=0,x5=0|y=-1)p(y=-1) = 0.00185185185185 \n",
      "because 0.009375 is greater than  0.00185185185185  the predicted class is Y= 1 for 0  0 0 0 0\n",
      "\n",
      "for 1 1 0 1 0 \n",
      "Because P(X2=1|Y=Read) is equal to zero and as its not mentioned to use smoothing or adding an alpha,I leave it az 0\n",
      "P(x1=1,x2=1,x3=0,x4=1,x5=0|y=1)p(y=1) = 0.0\n",
      "P(x1=1,x2=1,x3=0,x4=1,x5=0|y=-1)p(y=-1) = 0.0462962962963\n",
      "Y= -1 is predicted as it maximizes likelihood for 1 1 0 1 0 \n",
      "\n",
      "c)\n",
      "As its not mentioned to smooth or add an alpha in case if a probablity of an independent variable for a given class\n",
      "is Zero, the posterior probability P(Y=+1|x1=1,x2=1,x3=0,x4=1,x5=1) equals to Zero , because P(X2=1|Y=+1)= 0 and\n",
      "then P(x1=1,x2=1,x3=0,x4=1,x5=0|y=1)p(Y=+1) = 0.0\n",
      "\n",
      "d)\n",
      "If we use joint Bayes classifier then our join distribution table would be order O((number of features) power 2))\n",
      "as opposed to Naive Bayes Classifier which is linear and is order O( number of features )as we assume that each variable is independent\n",
      "\n",
      "e)\n",
      "In Naive Bayes we assume that all vairables are independent ,\n",
      "so being not able to tell whether we know the author or not , we still can use our model\n",
      "using other variables X2...X5 for  prediction purpose\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "Read = 1\n",
    "Not_Read = -1\n",
    "NumberOfFeatures=5\n",
    "NumberOfTrainingData = 10 \n",
    "\n",
    "Probablities_X_1_Y_Read = np.empty(NumberOfFeatures) # five is number of independent features \n",
    "Probablities_X_1_Y_Not_Read = np.empty(NumberOfFeatures)\n",
    "\n",
    "D  = np.empty([NumberOfTrainingData,NumberOfFeatures+1])\n",
    "\n",
    "\n",
    "D[0,] = [0,0,1,1,0,-1]\n",
    "D[1,] = [1,1,0,1,0,-1]\n",
    "D[2,] = [0,1,1,1,1,-1]\n",
    "D[3,] = [1,1,1,1,0,-1]\n",
    "D[4,] = [0,1,0,0,0,-1]\n",
    "D[5,] = [1,0,1,1,1,1]\n",
    "D[6,] = [0,0,1,0,0,1]\n",
    "D[7,] = [1,0,0,0,0,1]\n",
    "D[8,] = [1,0,1,1,0,1]\n",
    "D[9,] = [1,1,1,1,1,-1]\n",
    "\n",
    "Prob_Y_Read = sum(D[:,-1] == Read)/NumberOfTrainingData\n",
    "Prob_Y_Not_Read = 1-Prob_Y_Read\n",
    "\n",
    "print(\"a)\")\n",
    "print(\"P(Y=1) is equal to \"+str(Prob_Y_Read))   # P(Y=1) = 0.4\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# P(Xi=1|Y=1)\n",
    "for i in range(NumberOfFeatures):\n",
    "  Probablities_X_1_Y_Read[i] = 0 \n",
    "  Y_Read_Count = 0 \n",
    "  for EachTrainingData in range(NumberOfTrainingData):\n",
    "      if (D[EachTrainingData,NumberOfFeatures] == Read ):\n",
    "         Y_Read_Count += 1 \n",
    "         if (D[EachTrainingData,i] == True):\n",
    "              Probablities_X_1_Y_Read[i] += 1 \n",
    "              \n",
    "  Probablities_X_1_Y_Read[i] /=   Y_Read_Count            \n",
    "\n",
    "#Result is   --> P (Xi=1|Y=1)  [ 0.75  0.    0.75  0.5   0.25]\n",
    "print(\"P (Xi=1|Y=1)  [ 0.75  0.    0.75  0.5   0.25]  \")\n",
    "\n",
    "# P(Xi=1|Y=-1)\n",
    "for i in range(NumberOfFeatures):\n",
    "  Probablities_X_1_Y_Not_Read[i] = 0 \n",
    "  Y_Read_Count = 0 \n",
    "  for EachTrainingData in range(NumberOfTrainingData):\n",
    "      if (D[EachTrainingData,NumberOfFeatures] == Not_Read ):\n",
    "         Y_Read_Count += 1 \n",
    "         if (D[EachTrainingData,i] == True):\n",
    "              Probablities_X_1_Y_Not_Read[i] += 1 \n",
    "              \n",
    "  Probablities_X_1_Y_Not_Read[i] /=   Y_Read_Count \n",
    "\n",
    "#Result is  --> P(Xi=1|Y=-1) [ 0.5  0.83333333  0.66666667  0.83333333  0.33333333]\n",
    "print(\"P(Xi=1|Y=-1) [ 0.5  0.83333333  0.66666667  0.83333333  0.33333333])\")\n",
    "\n",
    "\n",
    "# which one maximizes ? -- > P(Y=1 | X = 0 0 0 0 0)  ? P P(Y=-1 | X = 0 0 0 0 0)\n",
    "# let's calculate which the one that maximize is the Class for x= 0 0 0 0 0 \n",
    "\n",
    "# no need to calculate Denominator , just numerator is calculated as denominators are equal\n",
    "\n",
    "# lets Calculate P(Y=1 | x = 0 0 0 0 0 )\n",
    "Prob_X_0_0_0_0_0_Y_Read = 1-Probablities_X_1_Y_Read[0]\n",
    "for i in range(NumberOfFeatures-1):\n",
    "    Prob_X_0_0_0_0_0_Y_Read *= (1-Probablities_X_1_Y_Read[i+1])\n",
    "Prob_X_0_0_0_0_0_Y_Read *=  Prob_Y_Read\n",
    "\n",
    "#Prob_X_0_0_0_0_0_Y_Read = 0.009375\n",
    "\n",
    "\n",
    "\n",
    "# lets Calculate P(Y=-1 | x = 0 0 0 0 0 )\n",
    "Prob_X_0_0_0_0_0_Not_Y_Read = 1-Probablities_X_1_Y_Not_Read[0]\n",
    "for i in range(NumberOfFeatures-1):\n",
    "    Prob_X_0_0_0_0_0_Not_Y_Read *= (1-Probablities_X_1_Y_Not_Read[i+1])\n",
    "Prob_X_0_0_0_0_0_Not_Y_Read *=  Prob_Y_Not_Read\n",
    "#Prob_X_0_0_0_0_0_Not_Y_Read  = 0.00185185185185\n",
    "print(\"\\nb)\\nfor  0 0 0 0 0\")\n",
    "print(\"p(x1=0,x2=0,x3=0,x4=0,x5=0|y=1)p(y=1) = 0.009375 \")\n",
    "print(\"p(x1=0,x2=0,x3=0,x4=0,x5=0|y=-1)p(y=-1) = 0.00185185185185 \")      \n",
    "print(\"because 0.009375 is greater than  0.00185185185185 \"\\\n",
    "      \" the predicted class is Y= 1 for 0  0 0 0 0\")\n",
    "\n",
    "# which one maximizes ? -- > P(Y=1 | X = 1 1 0 1 0)  ? P P(Y=-1 | X = 1 1 0 1 0)\n",
    "# let's calculate which the one that maximize is the Class for x= 1 1 0 1 0 \n",
    "\n",
    "# lets Calculate P(Y=1 | x = 1 1 0 1 0 )\n",
    "Prob_X_1_1_0_1_0_Y_Read   =  (Probablities_X_1_Y_Read[0] *Probablities_X_1_Y_Read[1]*Probablities_X_1_Y_Read[3])\n",
    "Prob_X_1_1_0_1_0_Y_Read  *=  ((1-Probablities_X_1_Y_Read[2]) * (1-Probablities_X_1_Y_Read[4]))\n",
    "Prob_X_1_1_0_1_0_Y_Read  *=  Prob_Y_Read\n",
    "\n",
    "#Prob_X_1_1_0_1_0_Y_Read = 0.0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# lets Calculate P(Y=-1 | x = 1 1 0 1 0 )\n",
    "Prob_X_1_1_0_1_0_Y_Not_Read   =  (Probablities_X_1_Y_Not_Read[0] *Probablities_X_1_Y_Not_Read[1]*Probablities_X_1_Y_Not_Read[3])\n",
    "Prob_X_1_1_0_1_0_Y_Not_Read  *=  ((1-Probablities_X_1_Y_Not_Read[2]) * (1-Probablities_X_1_Y_Not_Read[4]))\n",
    "Prob_X_1_1_0_1_0_Y_Not_Read  *=  Prob_Y_Not_Read\n",
    "\n",
    "#Prob_X_1_1_0_1_0_Y_Not_Read  = 0.0462962962963\n",
    "\n",
    "print(\"\\nfor 1 1 0 1 0 \\nBecause P(X2=1|Y=Read) is equal to zero and as its not mentioned\"\\\n",
    "      \" to use smoothing or adding an alpha,I leave it az 0\")\n",
    "print(\"P(x1=1,x2=1,x3=0,x4=1,x5=0|y=1)p(y=1) = 0.0\")\n",
    "print(\"P(x1=1,x2=1,x3=0,x4=1,x5=0|y=-1)p(y=-1) = 0.0462962962963\")      \n",
    "print(\"Y= -1 is predicted as it maximizes likelihood for 1 1 0 1 0 \\n\")\n",
    "\n",
    "\n",
    "# lets Calculate P(Y= 1 | x = 1 1 0 1 0 )\n",
    "Prob_Y_Read_X_1_1_0_1_0 = Prob_X_1_1_0_1_0_Y_Read  / ( Prob_X_1_1_0_1_0_Y_Read + Prob_X_1_1_0_1_0_Y_Not_Read ) \n",
    "\n",
    "print(\"c)\\nAs its not mentioned to smooth or add an alpha in case if a probablity of an independent\"\\\n",
    "      \" variable for a given class\\nis Zero, the posterior probability P(Y=+1|x1=1,x2=1,x3=0,x4=1,x5=1)\"\\\n",
    "     \" equals to Zero , because P(X2=1|Y=+1)= 0 and\\nthen P(x1=1,x2=1,x3=0,x4=1,x5=0|y=1)p(Y=+1) = 0.0\")\n",
    "     \n",
    "    \n",
    "print(\"\\nd)\\nIf we use joint Bayes classifier then our join distribution table would be \"\\\n",
    "      \"order O((number of features) power 2))\")\n",
    "print(\"as opposed to Naive Bayes Classifier which is linear and is order O( number of features )\"\\\n",
    "      \"as we assume that each variable is independent\\n\")\n",
    "\n",
    "print(\"e)\\nIn Naive Bayes we assume that all vairables are independent ,\")\n",
    "print(\"so being not able to tell whether we know the author or not , we still can use our model\")\n",
    "print(\"using other variables X2...X5 for  prediction purpose\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
